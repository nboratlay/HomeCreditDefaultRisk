{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b8c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from csv import DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a453f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_pay_data_path = r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\installments_payments_sorted_by_days_installment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f7589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997752\n"
     ]
    }
   ],
   "source": [
    "# number of id to preprocess -- nearly 1 million!\n",
    "df = pd.read_csv(ins_pay_data_path)\n",
    "id_prev_to_preprocess = df.SK_ID_PREV.unique()\n",
    "print(len(id_prev_to_preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24342626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rows_by_months(df):\n",
    "    \n",
    "    first_day = df['DAYS_INSTALMENT'].values[0] - 0.1\n",
    "    last_day = df['DAYS_INSTALMENT'].values[len(df) - 1] - 0.1\n",
    "    \n",
    "    # make bins using the first & last days, with 30 days interval\n",
    "    days_in_a_month = 30\n",
    "    my_bin = list(np.arange(first_day, last_day + days_in_a_month, days_in_a_month))\n",
    "\n",
    "    df['group'] = np.digitize(df['DAYS_INSTALMENT'], bins=my_bin)\n",
    "    df_grouped = df.groupby(['group'])\n",
    "    \n",
    "    # faster than groupby(['group']).agg{...}\n",
    "    df_new = pd.DataFrame({'DAYS_INSTALMENT': df_grouped['DAYS_INSTALMENT'].mean(), \n",
    "                           'DAYS_ENTRY_PAYMENT': df_grouped['DAYS_ENTRY_PAYMENT'].mean(),\n",
    "                           'AMT_INSTALMENT': df_grouped['AMT_INSTALMENT'].sum(),\n",
    "                           'AMT_PAYMENT': df_grouped['AMT_PAYMENT'].sum(),\n",
    "                            })\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21403354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(id_prev, df_grouped):\n",
    "    dict_for_this_sk_id = {}\n",
    "    dict_for_this_sk_id[\"SK_ID_PREV\"] = id_prev\n",
    "\n",
    "    # if there is only 1 installment (regardless of how many days ago)\n",
    "    if len(df_grouped) < 2:\n",
    "        dict_for_this_sk_id[\"DEFAULT\"] = False\n",
    "        dict_for_this_sk_id[\"STDEV_PAYMENTS\"] = 0\n",
    "        \n",
    "        # has that installment actually been paid?\n",
    "        no_payment_flag = df_grouped[\"AMT_PAYMENT\"].values[0] == 0.0\n",
    "        \n",
    "        if no_payment_flag:\n",
    "            # can't be paying 'late' if hasn't paid yet lol\n",
    "            dict_for_this_sk_id[\"MEAN_DAYS_LATE\"] = np.nan\n",
    "        else:\n",
    "            dict_for_this_sk_id[\"MEAN_DAYS_LATE\"] = df_grouped[\"DAYS_ENTRY_PAYMENT\"].values[0] - df_grouped[\"DAYS_INSTALMENT\"].values[0]\n",
    "        return dict_for_this_sk_id\n",
    "\n",
    "    # use to decide whether the person went broke -- one usual pattern is more than 3 NAs in the end\n",
    "    num_rows_with_na = df_grouped.isna().any(axis=1).sum()\n",
    "    \n",
    "    # how much does the person owe the bank in total\n",
    "    money_owed = df_grouped[\"AMT_INSTALMENT\"].sum() - df_grouped[\"AMT_PAYMENT\"].sum()\n",
    "    \n",
    "    # how much money does the person owe, comparing with their usual monthly instalment\n",
    "    percentage_instalment_owed = money_owed/df_grouped[\"AMT_INSTALMENT\"].mean()\n",
    "    \n",
    "    # default conditions: \n",
    "    # more than 3 rows with na values \n",
    "    # money_owed > 10000 \n",
    "    # percentage_instalment_owed > 20% of avg instalment\n",
    "    default_conditions_bool = (num_rows_with_na > 3) & \\\n",
    "                            (money_owed > 10000) & \\\n",
    "                            (percentage_instalment_owed > 0.2) \n",
    "    \n",
    "    dict_for_this_sk_id[\"DEFAULT\"] = default_conditions_bool\n",
    "    \n",
    "    # STDEV_PAYMENTS and MEAN_DAYS_LATE calculation should ignore nans and zeroes\n",
    "    df_rows_without_na = df_grouped[~df_grouped.isna().any(axis=1)]\n",
    "    dict_for_this_sk_id[\"STDEV_PAYMENTS\"] = df_rows_without_na[\"AMT_PAYMENT\"].std()\n",
    "    dict_for_this_sk_id[\"MEAN_DAYS_LATE\"] = df_rows_without_na[\"DAYS_ENTRY_PAYMENT\"].mean() - df_rows_without_na[\"DAYS_INSTALMENT\"].mean()\n",
    "\n",
    "    return dict_for_this_sk_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a60cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\redal\\AppData\\Local\\Temp/ipykernel_22128/274856962.py:27: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  percentage_instalment_owed = money_owed/df_grouped[\"AMT_INSTALMENT\"].mean()\n"
     ]
    }
   ],
   "source": [
    "# https://blog.samrid.me/how-to-save-python-objects-in-redis\n",
    "\n",
    "# OBSERVATION\n",
    "# start running at 16:53\n",
    "# ends at before 17:53\n",
    "# shortened to 1 hour! Yay!\n",
    "# within estimated time below\n",
    "\n",
    "# ESTIMATION\n",
    "# after optimisation:\n",
    "# time for row grouping < 0.005\n",
    "# time for extracting features < 0.003\n",
    "# misc ~0.02 (see %prune results)\n",
    "# total time < 0.01\n",
    "# i.e. about 1-2 hours for 997752 SK_ID_PREV\n",
    "# on top of this, for SK_ID_PREV with a single row, time ~0.0\n",
    "\n",
    "people_list = []\n",
    "\n",
    "with open(ins_pay_data_path, \"r\") as read_obj:\n",
    "    csv_reader = DictReader(read_obj)\n",
    "    id_dict_temp = []\n",
    "    id_dict = defaultdict(list)\n",
    "\n",
    "    current_id = '1000001'\n",
    "    for row in csv_reader:\n",
    "        row.pop('')\n",
    "        row.pop('Unnamed: 0')\n",
    "        if row['SK_ID_PREV'] == current_id:\n",
    "            id_dict_temp.append(row)\n",
    "        else:\n",
    "            # do all operations here!\n",
    "            for d in id_dict_temp: \n",
    "                for key, value in d.items():\n",
    "                    try:\n",
    "                        id_dict[key].append(float(value))\n",
    "                    except ValueError:\n",
    "                        id_dict[key].append(np.nan)\n",
    "            \n",
    "            df = pd.DataFrame.from_dict(id_dict)\n",
    "            \n",
    "            df_grouped = group_rows_by_months(df)\n",
    "            dict_features = extract_features(int(df['SK_ID_PREV'][0]), df)\n",
    "            people_list.append(dict_features)\n",
    "            \n",
    "            # update current_id and empty out the temporary lists again\n",
    "            current_id = row['SK_ID_PREV']\n",
    "            id_dict_temp = []\n",
    "            id_dict = defaultdict(list)\n",
    "            \n",
    "            # update the empty temp list with values of current row\n",
    "            id_dict_temp.append(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c52e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997751\n"
     ]
    }
   ],
   "source": [
    "print(len(people_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95deb3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dict_list is 8.448728 MB\n"
     ]
    }
   ],
   "source": [
    "size_in_bytes = sys.getsizeof(people_list) \n",
    "print(\"Size of the dict_list is {} MB\".format(size_in_bytes/1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b881123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save people_list to pickle for loss prevention\n",
    "with open(r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\insurance_data_list_of_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(people_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da2bdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the extracted features to csv file\n",
    "with open(r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\insurance_data_extracted_features.csv\", 'w', encoding='utf8', newline='') as output_file:\n",
    "    fc = csv.DictWriter(output_file, \n",
    "                        fieldnames=people_list[0].keys(),\n",
    "\n",
    "                       )\n",
    "    fc.writeheader()\n",
    "    fc.writerows(people_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64cb9693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# this cell is just to calculate the time needed to extract features for one single SK_ID_PREV\n",
    "\n",
    "def get_feature_dicts_of_all_id():\n",
    "\n",
    "    people_list = []\n",
    "\n",
    "    with open(ins_pay_data_path, \"r\") as read_obj:\n",
    "        csv_reader = DictReader(read_obj)\n",
    "        id_dict_temp = []\n",
    "        id_dict = defaultdict(list)\n",
    "\n",
    "        current_id = '1000001'\n",
    "        for row in csv_reader:\n",
    "            row.pop('')\n",
    "            row.pop('Unnamed: 0')\n",
    "            if row['SK_ID_PREV'] == current_id:\n",
    "                id_dict_temp.append(row)\n",
    "            else:\n",
    "                # do all operations here!\n",
    "                for d in id_dict_temp: \n",
    "                    for key, value in d.items():\n",
    "                        try:\n",
    "                            id_dict[key].append(float(value))\n",
    "                        except ValueError:\n",
    "                            id_dict[key].append(np.nan)\n",
    "            \n",
    "                df = pd.DataFrame.from_dict(id_dict)\n",
    "            \n",
    "                df_grouped = group_rows_by_months(df)\n",
    "                dict_features = extract_features(int(df['SK_ID_PREV'][0]), df)\n",
    "                people_list.append(dict_features)\n",
    "            \n",
    "                # update current_id and empty out the temporary lists again\n",
    "                current_id = row['SK_ID_PREV']\n",
    "                id_dict_temp = []\n",
    "                id_dict = defaultdict(list)\n",
    "            \n",
    "                # update the empty temp list with values of current row\n",
    "                id_dict_temp.append(row)\n",
    "                break\n",
    "\n",
    "%prun get_feature_dicts_of_all_id()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44137514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now just load the feature file, match SK_ID_PREV with SK_ID_CURR and then save the features by SK_ID_CURR into another file\n",
    "# this is needed only because I forgot to save SK_ID_CURR into feature file :)\n",
    "\n",
    "ins_pay_data_path = r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\installments_payments_sorted_by_days_installment.csv\"\n",
    "features_prev_data_path = r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\kahmin\\installments_payments_extracted_features.csv\"\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e16b7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158271</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101962</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>252457</td>\n",
       "      <td>1000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>260094</td>\n",
       "      <td>1000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>176456</td>\n",
       "      <td>1000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SK_ID_CURR  SK_ID_PREV\n",
       "0       158271     1000001\n",
       "2       101962     1000002\n",
       "6       252457     1000003\n",
       "9       260094     1000004\n",
       "16      176456     1000005"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_id_curr = pd.read_csv(ins_pay_data_path)\n",
    "\n",
    "col_needed = [\"SK_ID_CURR\", \"SK_ID_PREV\"]\n",
    "              \n",
    "df_id = df_id_curr[col_needed].drop_duplicates('SK_ID_PREV')\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a836c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_prev = pd.read_csv(features_prev_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ebd3c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>DEFAULT</th>\n",
       "      <th>STDEV_PAYMENTS</th>\n",
       "      <th>MEAN_DAYS_LATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158271</td>\n",
       "      <td>1000001</td>\n",
       "      <td>False</td>\n",
       "      <td>39339.747885</td>\n",
       "      <td>-16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101962</td>\n",
       "      <td>1000002</td>\n",
       "      <td>False</td>\n",
       "      <td>6089.782500</td>\n",
       "      <td>-19.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252457</td>\n",
       "      <td>1000003</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260094</td>\n",
       "      <td>1000004</td>\n",
       "      <td>False</td>\n",
       "      <td>3698.527885</td>\n",
       "      <td>-26.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176456</td>\n",
       "      <td>1000005</td>\n",
       "      <td>False</td>\n",
       "      <td>4432.077970</td>\n",
       "      <td>-8.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  SK_ID_PREV  DEFAULT  STDEV_PAYMENTS  MEAN_DAYS_LATE\n",
       "0      158271     1000001    False    39339.747885      -16.000000\n",
       "1      101962     1000002    False     6089.782500      -19.750000\n",
       "2      252457     1000003    False        0.000000      -15.333333\n",
       "3      260094     1000004    False     3698.527885      -26.714286\n",
       "4      176456     1000005    False     4432.077970       -8.454545"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_new = pd.merge(df_id, df_features_prev, on='SK_ID_PREV')\n",
    "df_features_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eb226bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_new.to_csv(path_or_buf=r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\kahmin\\insurance_data_extracted_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f2931d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw into pickle file\n",
    "with open(r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\kahmin\\insurance_data_list_of_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(df_features_new, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "feb06d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from pickle file\n",
    "with open(r\"C:\\Users\\redal\\Code\\bootcamp_ppi\\HomeCreditDefaultRisk\\HomeCreditDefaultRisk\\kahmin\\insurance_data_list_of_dict.pkl\", \"rb\") as input_file:\n",
    "    e = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5a00eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>DEFAULT</th>\n",
       "      <th>STDEV_PAYMENTS</th>\n",
       "      <th>MEAN_DAYS_LATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158271</td>\n",
       "      <td>1000001</td>\n",
       "      <td>False</td>\n",
       "      <td>39339.747885</td>\n",
       "      <td>-16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101962</td>\n",
       "      <td>1000002</td>\n",
       "      <td>False</td>\n",
       "      <td>6089.782500</td>\n",
       "      <td>-19.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252457</td>\n",
       "      <td>1000003</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260094</td>\n",
       "      <td>1000004</td>\n",
       "      <td>False</td>\n",
       "      <td>3698.527885</td>\n",
       "      <td>-26.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>176456</td>\n",
       "      <td>1000005</td>\n",
       "      <td>False</td>\n",
       "      <td>4432.077970</td>\n",
       "      <td>-8.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997746</th>\n",
       "      <td>292375</td>\n",
       "      <td>2843494</td>\n",
       "      <td>False</td>\n",
       "      <td>628430.873982</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997747</th>\n",
       "      <td>260963</td>\n",
       "      <td>2843495</td>\n",
       "      <td>False</td>\n",
       "      <td>239114.242278</td>\n",
       "      <td>-3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997748</th>\n",
       "      <td>425374</td>\n",
       "      <td>2843496</td>\n",
       "      <td>False</td>\n",
       "      <td>15722.730938</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997749</th>\n",
       "      <td>451578</td>\n",
       "      <td>2843497</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997750</th>\n",
       "      <td>393881</td>\n",
       "      <td>2843498</td>\n",
       "      <td>False</td>\n",
       "      <td>129483.904121</td>\n",
       "      <td>-12.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997751 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  SK_ID_PREV  DEFAULT  STDEV_PAYMENTS  MEAN_DAYS_LATE\n",
       "0           158271     1000001    False    39339.747885      -16.000000\n",
       "1           101962     1000002    False     6089.782500      -19.750000\n",
       "2           252457     1000003    False        0.000000      -15.333333\n",
       "3           260094     1000004    False     3698.527885      -26.714286\n",
       "4           176456     1000005    False     4432.077970       -8.454545\n",
       "...            ...         ...      ...             ...             ...\n",
       "997746      292375     2843494    False   628430.873982      -10.000000\n",
       "997747      260963     2843495    False   239114.242278       -3.857143\n",
       "997748      425374     2843496    False    15722.730938       -4.000000\n",
       "997749      451578     2843497    False        0.000000       -2.900000\n",
       "997750      393881     2843498    False   129483.904121      -12.666667\n",
       "\n",
       "[997751 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da911f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
